{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"You are an AI assistant that is able to convert natural language into a properly formatted SQL query.\n",
    "\n",
    "The table you will be querying is called \"finances\". Here is the schema of the table:\n",
    "'finances': {'id': 'INTEGER', 'date': 'TEXT', 'revenue': 'REAL', 'expenses': 'REAL', 'profit': 'REAL'}\n",
    "\n",
    "You must always output your answer in a JSON document with the following key-value pairs:\n",
    "- \"query\": the SQL query that you generated\n",
    "- \"error\": an error message if the query is invalid, or null if the query is valid\n",
    "\n",
    "Output only the JSON document, nothing else.\n",
    "\n",
    "Here is an example if how the output should look like:\n",
    "{\n",
    "    \"query\": \"SELECT * FROM finances WHERE expenses > 1000\",\n",
    "    \"error\": null\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"Give an example of an SQL statement\"\n",
    "\n",
    "messages = [\n",
    "        {'role': 'system', 'content': SYSTEM_MESSAGE},\n",
    "        {'role': 'user', 'content': f\"{user_message}\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://anforsbe-sweden-central.openai.azure.com/\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  engine=\"gpt-4\",\n",
    "  messages = messages,\n",
    "  temperature=0.0,\n",
    "  max_tokens=800,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response.choices[0].message[\"content\"]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = json.loads(response)\n",
    "query = json_response['query']\n",
    "query\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas AI with AzureOpenAI\n",
    "\n",
    "*Working with Agent*\n",
    "\n",
    "With the chat agent, you can engage in dynamic conversations where the agent retains context throughout the discussion. This enables you to have more interactive and meaningful exchanges.\n",
    "\n",
    "Key Features\n",
    "\n",
    "Context Retention: The agent remembers the conversation history, allowing for seamless, context-aware interactions.\n",
    "\n",
    "Clarification Questions: You can use the clarification_questions method to request clarification on any aspect of the conversation. This helps ensure you fully understand the information provided.\n",
    "\n",
    "Explanation: The explain method is available to obtain detailed explanations of how the agent arrived at a particular solution or response. It offers transparency and insights into the agent's decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "from pandasai import Agent\n",
    "from pandasai.skills import skill\n",
    "# from pandasai import SmartDataframe\n",
    "\n",
    "from pandasai.llm.azure_openai import AzureOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_data = {\n",
    "    \"EmployeeID\": [1, 2, 3, 4, 5],\n",
    "    \"Name\": [\"John\", \"Emma\", \"Liam\", \"Olivia\", \"William\"],\n",
    "    \"Department\": [\"HR\", \"Sales\", \"IT\", \"Marketing\", \"Finance\"],\n",
    "}\n",
    "\n",
    "salaries_data = {\n",
    "    \"EmployeeID\": [1, 2, 3, 4, 5],\n",
    "    \"Salary\": [5000, 6000, 4500, 7000, 5500],\n",
    "}\n",
    "\n",
    "employees_df = pd.DataFrame(employees_data)\n",
    "salaries_df = pd.DataFrame(salaries_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "azure_openai_api_type = os.getenv(\"AZURE_OPENAI_API_TYPE\")\n",
    "azure_openai_api_base = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_API_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(api_token=azure_openai_api_key, \n",
    "            api_base=azure_openai_api_base,\n",
    "            api_version=azure_openai_api_version,\n",
    "            deployment_name=\"gpt-4-pandas-ai\", \n",
    "            is_chat_model=True)\n",
    "\n",
    "user_defined_path = \"LLM_play\\charts_saved\"\n",
    "\n",
    "# llm = AzureOpenAI(api_token=AZURE_OPENAI_API_KEY, api_base=openai_api_base,api_version=openai_api_version,deployment_name=\"gpt-4\", is_chat_model=True)\n",
    "#agent = Agent([employees_df, salaries_df], config={\"llm\": llm}, memory_size=10)\n",
    "\n",
    "agent = Agent([employees_df, salaries_df], config={\"llm\": llm, \"save_charts\": True, \"save_charts_path\": user_defined_path}, memory_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a custom skill\n",
    "# Note: That the function doc string give more context to the model for use this skill\n",
    "@skill\n",
    "def plot_horisontal_bar_capital_names(name_lst: list[str], salaries: list[int]):\n",
    "    \"\"\"\n",
    "    Displays the a horizontal bar chart having name on y axis and salaries on x axis where the names will be captial letters\n",
    "    Args:\n",
    "        name (list[str]): Employee name\n",
    "        salaries (list[int]): Salaries\n",
    "    \"\"\"\n",
    "    # plot bars\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    new_lst = []\n",
    "\n",
    "    for name in name_lst:\n",
    "        new_lst.append(name.upper())\n",
    "\n",
    "    new_lst\n",
    "\n",
    "    plt.barh(new_lst, salaries)\n",
    "    # plt.bar(new_lst, salaries_data[\"Salary\"])\n",
    "    plt.xlabel(\"Salary\")\n",
    "    plt.ylabel(\"EMPLOYEE NAMES\")\n",
    "    plt.title(\"Employee Salaries from a custom skill\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If hte skill is already added it will show upan an error message if added again. Hence in a try excpet\n",
    "try: \n",
    "    agent.add_skills(plot_horisontal_bar_capital_names)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with the agent\n",
    "response = agent.chat(\"What is the highet salary?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with the agent\n",
    "response = agent.chat(\"Who gets paid the most?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with the agent\n",
    "response = agent.chat(\"Plot a pie chart of the department distribution\")\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with the agent\n",
    "response = agent.chat(\"Create a boxplot of the salaries\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO save the image from pandas ai and then read it back \n",
    "# https://docs.streamlit.io/library/api-reference/media/st.image\n",
    "# https://docs.pandas-ai.com/en/latest/examples/#saving-plots-with-user-defined-path\n",
    "# Create a function to retreive an image and then remove it and then use streamlit to show it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_image_in_folder(folder_path):\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Filter only image files (you can customize this condition)\n",
    "    image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No image files found in the folder.\")\n",
    "        return None\n",
    "\n",
    "    # Get the first image file\n",
    "    first_image_path = os.path.join(folder_path, image_files[0])\n",
    "\n",
    "    # Open the image using Pillow\n",
    "    image = Image.open(first_image_path)\n",
    "\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = \"LLM_play\\charts_saved\"\n",
    "first_image = get_first_image_in_folder(folder_path)\n",
    "\n",
    "if first_image:\n",
    "    first_image.show()  # Opens the image using the default image viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(first_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_png_files(folder_path):\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Filter only PNG files\n",
    "    png_files = [file for file in files if file.lower().endswith('.png')]\n",
    "\n",
    "    if not png_files:\n",
    "        print(\"No PNG files found in the folder.\")\n",
    "        return\n",
    "\n",
    "    # Remove each PNG file\n",
    "    for png_file in png_files:\n",
    "        file_path = os.path.join(folder_path, png_file)\n",
    "        os.remove(file_path)\n",
    "        print(f\"Removed: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "folder_path = \"LLM_play\\charts_saved\"\n",
    "remove_png_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_app_folder.support_functions import SupportMainApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_app_folder.support_functions import SupportMainApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = SupportMainApp.get_first_png_image_in_folder(folder_path=\"temp_charts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SupportMainApp.remove_png_files(folder_path=\"temp_charts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_azure_openai import PandasAIClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_no_chart = PandasAIClass.return_pandas_agent_no_chart(subset_data=salaries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response_image:\n",
    "    print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_image = \"image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_image == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"temp_chart.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
